{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training for Emotion Recognition\n",
    "\n",
    "This notebook demonstrates how to train emotion recognition models using the implemented components.\n",
    "\n",
    "**What we'll do:**\n",
    "1. Load the dataset using our data loading pipeline\n",
    "2. Create models (ResNet18, EfficientNet-B0)\n",
    "3. Train with different loss functions (MSE, L1, KL Divergence)\n",
    "4. Monitor training with TensorBoard\n",
    "5. Save and load checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import our custom modules\n",
    "from src.models import create_model\n",
    "from src.losses import get_loss_function\n",
    "from src.train import create_trainer\n",
    "from src.utils import get_device, set_seed, count_parameters\n",
    "\n",
    "# Import data loading from previous notebook\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "set_seed(42)\n",
    "\n",
    "# Get device\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset\n",
    "\n",
    "We'll reuse the `EmotionDataset` class from the data loading notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotion labels\n",
    "EMOTION_LABELS = [\n",
    "    'neutral', 'happy', 'sad', 'surprised', 'fear', 'disgust', 'angry',\n",
    "    'contempt', 'serene', 'contemplative', 'secure', 'untroubled', 'quiet'\n",
    "]\n",
    "\n",
    "class EmotionDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for emotion recognition with probability distributions.\"\"\"\n",
    "    \n",
    "    def __init__(self, images_dir, annots_dir, transform=None, target_transform=None):\n",
    "        self.images_dir = Path(images_dir)\n",
    "        self.annots_dir = Path(annots_dir)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "        # Get all image files\n",
    "        self.image_files = sorted(\n",
    "            list(self.images_dir.glob('*.jpg')) + \n",
    "            list(self.images_dir.glob('*.png'))\n",
    "        )\n",
    "        \n",
    "        self._verify_annotations()\n",
    "        \n",
    "    def _verify_annotations(self):\n",
    "        \"\"\"Verify all images have corresponding annotation files.\"\"\"\n",
    "        valid_files = []\n",
    "        for img_path in self.image_files:\n",
    "            annot_path = self.annots_dir / f\"{img_path.stem}_prob_rank.txt\"\n",
    "            if annot_path.exists():\n",
    "                valid_files.append(img_path)\n",
    "        \n",
    "        self.image_files = valid_files\n",
    "        print(f\"‚úì Verified {len(self.image_files)} samples in {self.images_dir.parent.name}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = self.image_files[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Load probabilities (comma-separated)\n",
    "        annot_path = self.annots_dir / f\"{img_path.stem}_prob_rank.txt\"\n",
    "        with open(annot_path, 'r') as f:\n",
    "            line = f.read().strip()\n",
    "            probs = np.array([float(val) for val in line.split(',')], dtype=np.float32)\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if self.target_transform:\n",
    "            probs = self.target_transform(probs)\n",
    "        \n",
    "        probs = torch.from_numpy(probs)\n",
    "        \n",
    "        return image, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths\n",
    "DATASET_ROOT = Path('AffectNetFused')\n",
    "TRAIN_IMAGES_DIR = DATASET_ROOT / 'train_set' / 'images'\n",
    "TRAIN_ANNOTS_DIR = DATASET_ROOT / 'train_set' / 'annotations'\n",
    "VAL_IMAGES_DIR = DATASET_ROOT / 'val_set' / 'images'\n",
    "VAL_ANNOTS_DIR = DATASET_ROOT / 'val_set' / 'annotations'\n",
    "\n",
    "# Image transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = EmotionDataset(TRAIN_IMAGES_DIR, TRAIN_ANNOTS_DIR, transform=train_transform)\n",
    "val_dataset = EmotionDataset(VAL_IMAGES_DIR, VAL_ANNOTS_DIR, transform=val_transform)\n",
    "\n",
    "# Create dataloaders\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "print(f\"\\n‚úì DataLoaders ready:\")\n",
    "print(f\"  Training: {len(train_dataset)} samples, {len(train_loader)} batches\")\n",
    "print(f\"  Validation: {len(val_dataset)} samples, {len(val_loader)} batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create and Inspect Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model\n",
    "model = create_model('resnet18', pretrained=True, num_emotions=13)\n",
    "print(f\"\\n‚úì Created model: {model}\")\n",
    "\n",
    "# Count parameters\n",
    "params = count_parameters(model)\n",
    "print(f\"\\nüìä Model parameters:\")\n",
    "print(f\"  Total: {params['total']:,}\")\n",
    "print(f\"  Trainable: {params['trainable']:,}\")\n",
    "print(f\"  Non-trainable: {params['non_trainable']:,}\")\n",
    "\n",
    "# Test forward pass\n",
    "dummy_input = torch.randn(2, 3, 224, 224)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(dummy_input)\n",
    "\n",
    "print(f\"\\n‚úì Forward pass test:\")\n",
    "print(f\"  Input shape: {dummy_input.shape}\")\n",
    "print(f\"  Output shape: {output.shape}\")\n",
    "print(f\"  Output sums: {output.sum(dim=1)} (should be ~1.0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configure Training\n",
    "\n",
    "Choose loss function, optimizer, and other hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "EXPERIMENT_NAME = 'resnet18_mse'  # Change this for different experiments\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "LOSS_TYPE = 'mse'  # Options: 'mse', 'l1', 'kl', 'ce', 'js'\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è Training Configuration:\")\n",
    "print(f\"  Experiment: {EXPERIMENT_NAME}\")\n",
    "print(f\"  Model: ResNet18\")\n",
    "print(f\"  Loss: {LOSS_TYPE.upper()}\")\n",
    "print(f\"  Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"  Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"  Batch Size: {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fresh model for training\n",
    "model = create_model('resnet18', pretrained=True, num_emotions=13)\n",
    "\n",
    "# Create loss function\n",
    "loss_fn = get_loss_function(LOSS_TYPE)\n",
    "print(f\"\\n‚úì Loss function: {loss_fn}\")\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "print(f\"‚úì Optimizer: Adam (lr={LEARNING_RATE})\")\n",
    "\n",
    "# Learning rate scheduler (optional)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=3, verbose=True\n",
    ")\n",
    "print(f\"‚úì Scheduler: ReduceLROnPlateau\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Trainer and Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trainer\n",
    "trainer = create_trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    checkpoint_dir=f'checkpoints/{EXPERIMENT_NAME}',\n",
    "    log_dir=f'runs/{EXPERIMENT_NAME}',\n",
    "    metrics=['mse', 'kl', 'tvd']  # Metrics to track\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Trainer created!\")\n",
    "print(f\"  Checkpoints will be saved to: checkpoints/{EXPERIMENT_NAME}\")\n",
    "print(f\"  TensorBoard logs: runs/{EXPERIMENT_NAME}\")\n",
    "print(f\"\\nTo view training in TensorBoard, run:\")\n",
    "print(f\"  tensorboard --logdir=runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training!\n",
    "history = trainer.train(\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    scheduler=scheduler,\n",
    "    early_stopping_patience=5\n",
    ")\n",
    "\n",
    "# Save final model\n",
    "trainer.save_final_checkpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss curves\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "axes[0].plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training and Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Metrics\n",
    "if history['val_metrics']:\n",
    "    metric_name = list(history['val_metrics'][0].keys())[0]\n",
    "    metric_values = [m[metric_name] for m in history['val_metrics']]\n",
    "    axes[1].plot(metric_values, label=metric_name.upper(), linewidth=2, color='green')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Metric Value')\n",
    "    axes[1].set_title(f'Validation {metric_name.upper()}')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'checkpoints/{EXPERIMENT_NAME}/training_curves.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úì Training curves saved to: checkpoints/{EXPERIMENT_NAME}/training_curves.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Quick Predictions Visualization\n",
    "\n",
    "Let's see how the model performs on some validation samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import visualize_predictions\n",
    "\n",
    "# Get a batch from validation set\n",
    "images, targets = next(iter(val_loader))\n",
    "images = images.to(device)\n",
    "targets = targets.to(device)\n",
    "\n",
    "# Make predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(images)\n",
    "\n",
    "# Visualize\n",
    "fig = visualize_predictions(\n",
    "    images[:4], \n",
    "    predictions[:4], \n",
    "    targets[:4],\n",
    "    num_samples=4,\n",
    "    save_path=f'checkpoints/{EXPERIMENT_NAME}/sample_predictions.png'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Next Steps\n",
    "\n",
    "**To run more experiments:**\n",
    "\n",
    "1. **Try different loss functions:**\n",
    "   - Set `LOSS_TYPE = 'kl'` for KL Divergence\n",
    "   - Set `LOSS_TYPE = 'l1'` for L1 loss\n",
    "   - Set `LOSS_TYPE = 'ce'` for Cross-Entropy\n",
    "\n",
    "2. **Try different models:**\n",
    "   - `create_model('resnet50', pretrained=True)`\n",
    "   - `create_model('efficientnet_b0', pretrained=True)`\n",
    "\n",
    "3. **Adjust hyperparameters:**\n",
    "   - Learning rate: `LEARNING_RATE = 0.0001`\n",
    "   - Batch size: `BATCH_SIZE = 64`\n",
    "   - More epochs: `NUM_EPOCHS = 20`\n",
    "\n",
    "4. **View TensorBoard:**\n",
    "   ```bash\n",
    "   tensorboard --logdir=runs\n",
    "   ```\n",
    "   Then open http://localhost:6006 in your browser\n",
    "\n",
    "5. **Comprehensive evaluation:**\n",
    "   - See `03_evaluation.ipynb` for detailed model comparison\n",
    "   - See `04_visualization.ipynb` for qualitative analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "‚úì Loaded dataset with emotion probability distributions  \n",
    "‚úì Created and trained emotion recognition model  \n",
    "‚úì Tracked metrics with TensorBoard  \n",
    "‚úì Saved checkpoints for best model  \n",
    "‚úì Visualized predictions vs ground truth  \n",
    "\n",
    "The trained model is saved in `checkpoints/{EXPERIMENT_NAME}/best_model.pth`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
